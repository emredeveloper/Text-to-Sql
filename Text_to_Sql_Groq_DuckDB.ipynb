{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPW5R9SfvIYcHbhRXBcCR0R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emredeveloper/Text-to-Sql/blob/main/Text_to_Sql_Groq_DuckDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from groq import Groq\n",
        "import json\n",
        "import duckdb\n",
        "import sqlparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from colorama import Fore, Back, Style, init\n",
        "from tabulate import tabulate\n",
        "from pyfiglet import Figlet\n",
        "\n",
        "# Colorama'yı başlat\n",
        "init(autoreset=True)\n",
        "\n",
        "def chat_with_groq(client, prompt, model, response_format):\n",
        "    completion = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "        ],\n",
        "        response_format=response_format\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "def execute_duckdb_query(query):\n",
        "    original_cwd = os.getcwd()\n",
        "    os.chdir('data')\n",
        "    try:\n",
        "        conn = duckdb.connect(database=':memory:', read_only=False)\n",
        "        query_result = conn.execute(query).fetchdf().reset_index(drop=True)\n",
        "    finally:\n",
        "        os.chdir(original_cwd)\n",
        "    return query_result\n",
        "\n",
        "def get_summarization(client, user_question, df, model):\n",
        "    prompt = '''\n",
        "    A user asked the following question pertaining to local database tables:\n",
        "\n",
        "    {user_question}\n",
        "\n",
        "    To answer the question, a dataframe was returned:\n",
        "\n",
        "    Dataframe:\n",
        "    {df}\n",
        "\n",
        "    In a few sentences, summarize the data in the table as it pertains to the original user question. Avoid qualifiers like \"based on the data\" and do not comment on the structure or metadata of the table itself\n",
        "    '''.format(user_question=user_question, df=df)\n",
        "\n",
        "    return chat_with_groq(client, prompt, model, None)\n",
        "\n",
        "def print_fancy_title():\n",
        "    f = Figlet(font='slant')\n",
        "    print(Fore.CYAN + f.renderText('DuckDB Query Generator'))\n",
        "\n",
        "def print_menu():\n",
        "    print(Fore.YELLOW + \"\\n=== Menu ===\")\n",
        "    print(Fore.WHITE + \"1. Ask a question\")\n",
        "    print(Fore.WHITE + \"2. View query history\")\n",
        "    print(Fore.WHITE + \"3. Exit\")\n",
        "\n",
        "def print_query_result(sql_query, results_df, summarization, execution_time):\n",
        "    print(Fore.GREEN + \"\\n=== Query ===\")\n",
        "    print(Fore.WHITE + sqlparse.format(sql_query, reindent=True, keyword_case='upper'))\n",
        "\n",
        "    print(Fore.GREEN + \"\\n=== Results ===\")\n",
        "    print(tabulate(results_df, headers='keys', tablefmt='pretty', showindex=False))\n",
        "\n",
        "    print(Fore.GREEN + \"\\n=== Summary ===\")\n",
        "    print(Fore.WHITE + summarization)\n",
        "\n",
        "    print(Fore.CYAN + f\"\\nExecution time: {execution_time:.2f} seconds\")\n",
        "\n",
        "def main():\n",
        "    print_fancy_title()\n",
        "    print(Fore.WHITE + \"You can ask questions about the data in the 'employees.csv' and 'purchases.csv' files.\")\n",
        "\n",
        "    # Use the Llama3 70b model\n",
        "    model = \"llama3-70b-8192\"\n",
        "\n",
        "    # Get the Groq API key and create a Groq client\n",
        "    groq_api_key = \"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\"\n",
        "    client = Groq(api_key=groq_api_key)\n",
        "\n",
        "    # Load the base prompt\n",
        "    with open('prompts/base_prompt.txt', 'r') as file:\n",
        "        base_prompt = file.read()\n",
        "\n",
        "    query_history = []\n",
        "\n",
        "    while True:\n",
        "        print_menu()\n",
        "        choice = input(Fore.YELLOW + \"Enter your choice (1/2/3): \" + Fore.WHITE)\n",
        "\n",
        "        if choice == '1':\n",
        "            user_question = input(Fore.YELLOW + \"\\nAsk a question: \" + Fore.WHITE)\n",
        "\n",
        "            try:\n",
        "                full_prompt = base_prompt.format(user_question=user_question)\n",
        "\n",
        "                print(Fore.CYAN + \"\\nGenerating SQL query...\")\n",
        "                start_time = time.time()\n",
        "                llm_response = chat_with_groq(client, full_prompt, model, {\"type\": \"json_object\"})\n",
        "\n",
        "                result_json = json.loads(llm_response)\n",
        "                if 'sql' in result_json:\n",
        "                    sql_query = result_json['sql']\n",
        "                    print(Fore.CYAN + \"Executing query...\")\n",
        "                    results_df = execute_duckdb_query(sql_query)\n",
        "\n",
        "                    summarization = get_summarization(client, user_question, results_df, model)\n",
        "                    execution_time = time.time() - start_time\n",
        "\n",
        "                    print_query_result(sql_query, results_df, summarization, execution_time)\n",
        "\n",
        "                    query_history.append({\n",
        "                        'question': user_question,\n",
        "                        'sql': sql_query,\n",
        "                        'results': results_df,\n",
        "                        'summary': summarization,\n",
        "                        'time': execution_time\n",
        "                    })\n",
        "                elif 'error' in result_json:\n",
        "                    print(Fore.RED + \"ERROR: Could not generate valid SQL for this question\")\n",
        "                    print(Fore.RED + result_json['error'])\n",
        "\n",
        "            except Exception as e:\n",
        "                print(Fore.RED + f\"An error occurred: {str(e)}\")\n",
        "\n",
        "        elif choice == '2':\n",
        "            if not query_history:\n",
        "                print(Fore.YELLOW + \"\\nNo queries in history.\")\n",
        "            else:\n",
        "                for i, query in enumerate(query_history):\n",
        "                    print(Fore.CYAN + f\"\\n=== Query {i+1} ===\")\n",
        "                    print(Fore.WHITE + f\"Question: {query['question']}\")\n",
        "                    print(Fore.WHITE + f\"SQL: {query['sql']}\")\n",
        "                    print(Fore.WHITE + \"Results:\")\n",
        "                    print(tabulate(query['results'], headers='keys', tablefmt='pretty', showindex=False))\n",
        "                    print(Fore.WHITE + f\"Summary: {query['summary']}\")\n",
        "                    print(Fore.WHITE + f\"Execution time: {query['time']:.2f} seconds\")\n",
        "\n",
        "        elif choice == '3':\n",
        "            print(Fore.GREEN + \"Thank you for using the DuckDB Query Generator. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(Fore.RED + \"Invalid choice. Please try again.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HRi5GENnu9IH",
        "outputId": "2c2707ad-a9e6-4e8f-f6cd-96c5326e9aa0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ____             __   ____  ____     ____                       \n",
            "   / __ \\__  _______/ /__/ __ \\/ __ )   / __ \\__  _____  _______  __\n",
            "  / / / / / / / ___/ //_/ / / / __  |  / / / / / / / _ \\/ ___/ / / /\n",
            " / /_/ / /_/ / /__/ ,< / /_/ / /_/ /  / /_/ / /_/ /  __/ /  / /_/ / \n",
            "/_____/\\__,_/\\___/_/|_/_____/_____/   \\___\\_\\__,_/\\___/_/   \\__, /  \n",
            "                                                           /____/   \n",
            "   ______                           __            \n",
            "  / ____/__  ____  ___  _________ _/ /_____  _____\n",
            " / / __/ _ \\/ __ \\/ _ \\/ ___/ __ `/ __/ __ \\/ ___/\n",
            "/ /_/ /  __/ / / /  __/ /  / /_/ / /_/ /_/ / /    \n",
            "\\____/\\___/_/ /_/\\___/_/   \\__,_/\\__/\\____/_/     \n",
            "                                                  \n",
            "\n",
            "You can ask questions about the data in the 'employees.csv' and 'purchases.csv' files.\n",
            "\n",
            "=== Menu ===\n",
            "1. Ask a question\n",
            "2. View query history\n",
            "3. Exit\n",
            "\u001b[33mEnter your choice (1/2/3): \u001b[37m1\n",
            "\u001b[33m\n",
            "Ask a question: \u001b[37mget 5 empoloyees name\n",
            "\n",
            "Generating SQL query...\n",
            "Executing query...\n",
            "\n",
            "=== Query ===\n",
            "SELECT name\n",
            "FROM employees.csv AS employees\n",
            "LIMIT 5\n",
            "\n",
            "=== Results ===\n",
            "+-------------------+\n",
            "|       name        |\n",
            "+-------------------+\n",
            "| Richard Hendricks |\n",
            "|  Erlich Bachman   |\n",
            "|  Dinesh Chugtai   |\n",
            "| Bertram Gilfoyle  |\n",
            "|    Jared Dunn     |\n",
            "+-------------------+\n",
            "\n",
            "=== Summary ===\n",
            "The names of 5 employees are listed. They are Richard Hendricks, Erlich Bachman, Dinesh Chugtai, Bertram Gilfoyle, and Jared Dunn.\n",
            "\n",
            "Execution time: 0.68 seconds\n",
            "\n",
            "=== Menu ===\n",
            "1. Ask a question\n",
            "2. View query history\n",
            "3. Exit\n",
            "\u001b[33mEnter your choice (1/2/3): \u001b[37morder by names employees table\n",
            "Invalid choice. Please try again.\n",
            "\n",
            "=== Menu ===\n",
            "1. Ask a question\n",
            "2. View query history\n",
            "3. Exit\n",
            "\u001b[33mEnter your choice (1/2/3): \u001b[37m1\n",
            "\u001b[33m\n",
            "Ask a question: \u001b[37morder by names employees table\n",
            "\n",
            "Generating SQL query...\n",
            "Executing query...\n",
            "\n",
            "=== Query ===\n",
            "SELECT name\n",
            "FROM employees.csv AS employees\n",
            "ORDER BY name;\n",
            "\n",
            "=== Results ===\n",
            "+-------------------+\n",
            "|       name        |\n",
            "+-------------------+\n",
            "| Bertram Gilfoyle  |\n",
            "|  Dinesh Chugtai   |\n",
            "|  Erlich Bachman   |\n",
            "|   Gavin Belson    |\n",
            "|    Jared Dunn     |\n",
            "|    Monica Hall    |\n",
            "| Richard Hendricks |\n",
            "+-------------------+\n",
            "\n",
            "=== Summary ===\n",
            "The employees table contains a list of 7 names, with Bertram Gilfoyle at the top and Richard Hendricks at the bottom. The names are primarily masculine, with only one female name, Monica Hall. The names are a mix of simple (Jared Dunn) and more elaborated names (Bertram Gilfoyle, Erlich Bachman).\n",
            "\n",
            "Execution time: 0.63 seconds\n",
            "\n",
            "=== Menu ===\n",
            "1. Ask a question\n",
            "2. View query history\n",
            "3. Exit\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-f164cecdf3b1>\u001b[0m in \u001b[0;36m<cell line: 153>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-f164cecdf3b1>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mprint_menu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mchoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYELLOW\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Enter your choice (1/2/3): \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHITE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import streamlit as st\n",
        "from groq import Groq\n",
        "import json\n",
        "import duckdb\n",
        "import sqlparse\n",
        "import pandas as pd\n",
        "import time\n",
        "from colorama import Fore, Back, Style, init\n",
        "from tabulate import tabulate\n",
        "from pyfiglet import Figlet\n",
        "\n",
        "# Colorama'yı başlat\n",
        "init(autoreset=True)\n",
        "\n",
        "def chat_with_groq(client, prompt, model, response_format):\n",
        "    completion = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "        ],\n",
        "        response_format=response_format\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "def execute_duckdb_query(query):\n",
        "    original_cwd = os.getcwd()\n",
        "    os.chdir('data')\n",
        "    try:\n",
        "        conn = duckdb.connect(database=':memory:', read_only=False)\n",
        "        query_result = conn.execute(query).fetchdf().reset_index(drop=True)\n",
        "    finally:\n",
        "        os.chdir(original_cwd)\n",
        "    return query_result\n",
        "\n",
        "def get_summarization(client, user_question, df, model):\n",
        "    prompt = '''\n",
        "    A user asked the following question pertaining to local database tables:\n",
        "\n",
        "    {user_question}\n",
        "\n",
        "    To answer the question, a dataframe was returned:\n",
        "\n",
        "    Dataframe:\n",
        "    {df}\n",
        "\n",
        "    In a few sentences, summarize the data in the table as it pertains to the original user question. Avoid qualifiers like \"based on the data\" and do not comment on the structure or metadata of the table itself\n",
        "    '''.format(user_question=user_question, df=df)\n",
        "\n",
        "    return chat_with_groq(client, prompt, model, None)\n",
        "\n",
        "def print_fancy_title():\n",
        "    f = Figlet(font='slant')\n",
        "    st.text(Fore.CYAN + f.renderText('DuckDB Query Generator'))\n",
        "\n",
        "def print_menu():\n",
        "    st.text(Fore.YELLOW + \"\\n=== Menu ===\")\n",
        "    st.text(Fore.WHITE + \"1. Ask a question\")\n",
        "    st.text(Fore.WHITE + \"2. View query history\")\n",
        "    st.text(Fore.WHITE + \"3. Exit\")\n",
        "\n",
        "def print_query_result(sql_query, results_df, summarization, execution_time):\n",
        "    st.text(Fore.GREEN + \"\\n=== Query ===\")\n",
        "    st.text(Fore.WHITE + sqlparse.format(sql_query, reindent=True, keyword_case='upper'))\n",
        "\n",
        "    st.text(Fore.GREEN + \"\\n=== Results ===\")\n",
        "    st.dataframe(results_df)\n",
        "\n",
        "    st.text(Fore.GREEN + \"\\n=== Summary ===\")\n",
        "    st.text(Fore.WHITE + summarization)\n",
        "\n",
        "    st.text(Fore.CYAN + f\"\\nExecution time: {execution_time:.2f} seconds\")\n",
        "\n",
        "def main():\n",
        "    print_fancy_title()\n",
        "    st.text(Fore.WHITE + \"You can ask questions about the data in the 'employees.csv' and 'purchases.csv' files.\")\n",
        "\n",
        "    # Use the Llama3 70b model\n",
        "    model = \"llama3-70b-8192\"\n",
        "\n",
        "    # Get the Groq API key (replace with your actual key)\n",
        "    groq_api_key = \"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\"\n",
        "    client = Groq(api_key=groq_api_key)\n",
        "\n",
        "    # Load the base prompt\n",
        "    with open('prompts/base_prompt.txt', 'r') as file:\n",
        "        base_prompt = file.read()\n",
        "\n",
        "    query_history = []\n",
        "\n",
        "    menu_choice = st.selectbox(\"Choose an option:\", [\"Ask a question\", \"View query history\", \"Exit\"])\n",
        "\n",
        "    if menu_choice == \"Ask a question\":\n",
        "        user_question = st.text_input(\"Ask a question:\")\n",
        "\n",
        "        if st.button(\"Submit\"):\n",
        "            try:\n",
        "                full_prompt = base_prompt.format(user_question=user_question)\n",
        "\n",
        "                st.text(Fore.CYAN + \"\\nGenerating SQL query...\")\n",
        "                start_time = time.time()\n",
        "                llm_response = chat_with_groq(client, full_prompt, model, {\"type\": \"json_object\"})\n",
        "\n",
        "                result_json = json.loads(llm_response)\n",
        "                if 'sql' in result_json:\n",
        "                    sql_query = result_json['sql']\n",
        "                    st.text(Fore.CYAN + \"Executing query...\")\n",
        "                    results_df = execute_duckdb_query(sql_query)\n",
        "\n",
        "                    summarization = get_summarization(client, user_question, results_df, model)\n",
        "                    execution_time = time.time() - start_time\n",
        "\n",
        "                    print_query_result(sql_query, results_df, summarization, execution_time)\n",
        "\n",
        "                    query_history.append({\n",
        "                        'question': user_question,\n",
        "                        'sql': sql_query,\n",
        "                        'results': results_df,\n",
        "                        'summary': summarization,\n",
        "                        'time': execution_time\n",
        "                    })\n",
        "                elif 'error' in result_json:\n",
        "                    st.text(Fore.RED + \"ERROR: Could not generate valid SQL for this question\")\n",
        "                    st.text(Fore.RED + result_json['error'])\n",
        "\n",
        "            except Exception as e:\n",
        "                st.text(Fore.RED + f\"An error occurred: {str(e)}\")\n",
        "\n",
        "    elif menu_choice == \"View query history\":\n",
        "        if not query_history:\n",
        "            st.text(Fore.YELLOW + \"\\nNo queries in history.\")\n",
        "        else:\n",
        "            for i, query in enumerate(query_history):\n",
        "                st.text(Fore.CYAN + f\"\\n=== Query {i+1} ===\")\n",
        "                st.text(Fore.WHITE + f\"Question: {query['question']}\")\n",
        "                st.text(Fore.WHITE + f\"SQL: {query['sql']}\")\n",
        "                st.text(Fore.WHITE + \"Results:\")\n",
        "                st.dataframe(query['results'])\n",
        "                st.text(Fore.WHITE + f\"Summary: {query['summary']}\")\n",
        "                st.text(Fore.WHITE + f\"Execution time: {query['time']:.2f} seconds\")\n",
        "\n",
        "    elif menu_choice == \"Exit\":\n",
        "        st.text(Fore.GREEN + \"Thank you for using the DuckDB Query Generator. Goodbye!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNE57gZ71Hd5",
        "outputId": "dbc1a974-5fe7-4d25-ef4b-4a453442ca9a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xq4Jega31Lku",
        "outputId": "22ce1ee2-9635-4272-abf5-752d5fbeb925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.226.71.26\n",
            "\u001b[?25hnpx: installed 22 in 2.183s\n",
            "your url is: https://eleven-tigers-warn.loca.lt\n"
          ]
        }
      ]
    }
  ]
}